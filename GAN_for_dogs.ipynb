{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_for_dogs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FirangizSadiyeva/Covid-19/blob/main/GAN_for_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv1c3DQfs7mu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1a1a72-78bc-49cb-edff-8c3f2ee7fd9d"
      },
      "source": [
        "!pip install Adam"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Adam in /usr/local/lib/python3.7/dist-packages (0.0.0.dev0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_UcrYo_5ZcZ"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam # - Works\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Dense, Conv2D, Flatten, Reshape, Conv2DTranspose\n",
        "from keras.layers import LeakyReLU, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.utils.vis_utils import plot_model\n",
        "#from keras.utils import plot_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGlcyxkmtFuW"
      },
      "source": [
        "# define the discriminator model\n",
        "def define_D(in_shape=(128,128,3)):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQbjoQV-4LDG"
      },
      "source": [
        "# define the generator model\n",
        "def define_G(latent_dim):\n",
        "    model = Sequential()\n",
        "\t  # foundation for 16x16 image\n",
        "    n_nodes = 256 * 16 * 16\n",
        "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((16, 16, 256)))\n",
        "    # upsample to 32x32\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 64x64\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsamplde to 128x128\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(3, (7,7), activation='tanh', padding='same'))\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa3xOxeZ4VFR"
      },
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_GAN(model_G, model_D):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\tmodel_D.trainable = False\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(model_G)\n",
        "\tmodel.add(model_D)\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVLm4GnP535L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9ec530-cec1-4682-e6b8-d39986174f27"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGnTRM_C6FKb"
      },
      "source": [
        "def load_real_images():\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "    X = datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/dog_images',\n",
        "                                    target_size= (128,128),\n",
        "                                    batch_size=12500,\n",
        "                                    class_mode='binary')\n",
        "    data_list = []\n",
        "    batch_index = 0\n",
        "    while batch_index <= X.batch_index:\n",
        "        data = X.next()\n",
        "        data_list.append(data[0])\n",
        "        batch_index += 1\n",
        "    img_array = np.asarray(data_list)\n",
        "    return img_array"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYGf4um16L1J"
      },
      "source": [
        "def generate_real_images(dataset, n_samples):\n",
        "    i = np.random.randint(0, dataset.shape[0], n_samples)\n",
        "    X = dataset[i]\n",
        "    y = np.ones((n_samples,1))\n",
        "    return X, y"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqeEIt8I7oud"
      },
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    X = np.random.randn(latent_dim * n_samples)\n",
        "    X = X.reshape(n_samples, latent_dim)\n",
        "    return X"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CCPqyxa7rNO"
      },
      "source": [
        "def generate_fake_images(model_G, latent_dim, n_samples):\n",
        "    X_input = generate_latent_points(latent_dim, n_samples)\n",
        "    X = model_G.predict(X_input)\n",
        "    y = np.zeros((n_samples, 1))\n",
        "    return X, y"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN0KKHdk7vph"
      },
      "source": [
        "def summarize_performance(epoch, model_G, model_D, dataset, latent_dim, n_samples=100):\n",
        "  model_G.save('/content/drive/My Drive/Colab Notebooks/model_dog_' +str(epoch)+ '.h5')\n",
        "  X_real, y_real = generate_real_images(dataset, n_samples)\n",
        "  _, acc_real = model_D.evaluate(X_real, y_real, verbose=0)\n",
        "  x_fake, y_fake = generate_fake_images(model_G, latent_dim, n_samples)\n",
        "  _, acc_fake = model_D.evaluate(x_fake, y_fake, verbose=0)\n",
        "  print('Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1q6B3Nv8WEp"
      },
      "source": [
        "def train_discriminator(model, dataset, n_iter=100, n_batch=256):\n",
        "    half_batch = int(n_batch/2)\n",
        "    # manually enumerate epochs\n",
        "    for i in range(n_iter):\n",
        "        X_real, y_real = generate_real_images(dataset, half_batch)\n",
        "        _, real_acc = model.train_on_batch(X_real, y_real)\n",
        "        X_fake, y_fake = generate_fake_images(half_batch)\n",
        "        _, fake_acc = model.train_on_batch(X_fake, y_fake)\n",
        "        print('%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdS1fvDBA50K"
      },
      "source": [
        "def train_GAN(model_G, model_D, model_GAN, dataset, latent_dim, n_epochs=100, n_batch=128):\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# enumerate batches over the training set\n",
        "\t\tfor j in range(bat_per_epo):\n",
        "\t\t\tX_real, y_real = generate_real_images(dataset, half_batch)\n",
        "\t\t\tX_fake, y_fake = generate_fake_images(model_G, latent_dim, half_batch)\n",
        "\t\t\tX, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
        "\t\t\td_loss, _ = model_D.train_on_batch(X, y)\n",
        "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t\ty_gan = np.ones((n_batch, 1))\n",
        "\t\t\tg_loss = model_GAN.train_on_batch(X_gan, y_gan)\n",
        "\t\t\tprint('%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
        "\t\t# evaluate the model performance\n",
        "\t\tif (i+1) % 10 == 0:\n",
        "\t\t\tsummarize_performance(i, model_G, model_D, dataset, latent_dim)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BFNoRiUBEWE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "a63cf7d1-cbc1-4358-9d39-d1ba7669b894"
      },
      "source": [
        "latent_dim =100\n",
        "model_D = define_D()\n",
        "model_G = define_G(latent_dim)\n",
        "model_GAN = define_GAN(model_G, model_D)\n",
        "dataset=load_real_images()\n",
        "train_GAN(model_G, model_D,model_GAN,dataset[0], latent_dim)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-fc09b25d88e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_GAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_real_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_GAN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-eebd6d5c6e6f>\u001b[0m in \u001b[0;36mload_real_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                     class_mode='binary')\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/dog_images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMnxi8e1ldz-"
      },
      "source": [
        "model = load_model('/content/drive/My Drive/Colab Notebooks/model_face_79.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53g4qMZum2ob"
      },
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = np.random.randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn z_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR-_j3YQnCJ4"
      },
      "source": [
        "def plot_images(images, n):\n",
        "\t# scales image values in the range of [0,1]\n",
        "\timages = (images-images.min())/(images.max() - images.min())\n",
        "\tfor i in range(n):\n",
        "\t\t# define subplot\n",
        "\t\tplt.subplot(1, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tplt.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tplt.imshow(images[i, :, :])\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdzM4SL1nM-q"
      },
      "source": [
        "pts = generate_latent_points(100, 30)\n",
        "# generate images\n",
        "X = model.predict(pts)\n",
        "# plot the result\n",
        "plot_images(X, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDUCvDkBnVk2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}